{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9ckOeT7Oxn5qIRe1sOSsI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rion-user/Welcome/blob/master/%EC%9E%90%EB%A3%8C%EC%A1%B0%EC%82%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 자료조사"
      ],
      "metadata": {
        "id": "mYc-AgVrsJSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "링크\n",
        "\n",
        "[2023 인공지능 학습용 데이터 품질관리 가이드라인 및 구축 안내서 v3.0](https://www.nia.or.kr/site/nia_kor/ex/bbs/View.do?cbIdx=26537&bcIdx=25370&parentSeq=25370)\n",
        "\n",
        "[An Introduction to Machine Translation Quality Estimation](https://phrase.com/blog/posts/mt-quality-estimation/)\n",
        "\n",
        "\n",
        "\n",
        "keywords\n",
        "* TER(번역 편집 거리)\n",
        "* 기계번역 품질 예측 태스크\n",
        "* 기계번역 품질 예측 모델의 평가는 Matthews correlation coefficient (MCC)로 측정하며, f1 score도 함께 평가 지표로 제시됨\n"
      ],
      "metadata": {
        "id": "D95r6YE3sK_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 파파고 빨간펜\n",
        "* mqm 지표"
      ],
      "metadata": {
        "id": "g23KqukssiLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파파고 빨간펜 선생님\n",
        "> 번역모델 평가에는 크게 2가지 방식이 존재\n",
        "1. 전문가 평가 : 기계번역 모델간 품질을 가장 정확히 비교 및 평가하는 방법\n",
        "  - 시간 및 비용 측면에서 비쌈\n",
        "  - 평가 데이터 구축 필요함\n",
        "  - 현 ML 산업은 매우 fast-pace, 서비스 모델 개선/업데이트 인터벌이 짧음\n",
        "2. 자동 번역 평가\n",
        "  - 전문가 평가 대비 적은 비용과 시간 투입\n",
        "  - BLEU를 일반적으로 많이 쓰지만 정밀한(semantic) 평가 불가\n",
        "\n",
        "WMT 2020~2022 QE Shared Task 참여하며 자체 기술 고도화\n",
        "> QE Task는 목적에 따라 QE 모델의 예측값 형태도 다양함\n",
        "\n",
        "파파고는 똑똑해 <-> Papago is cute라는 세트가 존재할 때\n",
        "* Sentence-level QE : 0.3\n",
        "* Word-level QE : papago = Good, is = Good, cute = Bad\n",
        "* MQM word-level QE : cute = error_type : mistranslation, error_severity : major\n",
        "\n",
        "## 파파고 QE 모델 기술\n",
        "\n",
        "### 1. 인공 학습데이터 생성을 통해 데이터 양 / 언어쌍을 보강\n",
        "* 공개된 QE 모델을 사용하여 (원문, 번역문) 문장쌍에 대한 인공 레이블을 생성\n",
        "* 인공데이터를 학습에 추가 사용시, 모든 언어쌍에서 성능 향상\n",
        "\n",
        "### 2. Parallel Mining\n",
        "* Monolingual corpus를 NMT에 활용하는 방법\n",
        "* 모델 기반 : BART, MASS pretrain -> NMT fine-tune\n",
        "* 데이터 증강 기반 : Back-translation\n",
        "* 데이터 증강 기반 : Parallel Mining\n",
        "  * 대량의 한국어, 영어 말뭉치가 존재할 때 한-영 alignment를 탐색"
      ],
      "metadata": {
        "id": "FEEXHgvztoGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps3Iz4QysHY4"
      },
      "outputs": [],
      "source": []
    }
  ]
}