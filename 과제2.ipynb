{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AlC6ls4eJif8pVwnAIZsCN4fVvS7-rrg",
      "authorship_tag": "ABX9TyPMQhlwDNVAehchR56koAOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rion-user/Welcome/blob/master/%EA%B3%BC%EC%A0%9C2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnXM7yLRsF5u",
        "outputId": "eae9ecc2-7905-43a8-e545-416b6c0e2470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "h1zy23ApsQYX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> df v1.0"
      ],
      "metadata": {
        "id": "EpalwE7-KhBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/KB/df_type.csv')\n",
        "print(df['한국어'].apply(len).describe())\n",
        "df = df[(df['한국어'].apply(len)>26) & (df['한국어'].apply(len)<180)].reset_index(drop=True)\n",
        "for x in df.columns:\n",
        "  df[x] = df[x].apply(str.strip)\n",
        "c_list = ['관세','내국세','노동','상업,무역,공업','수산','농업','통화,국채,금융','축산','재정,경제일반','과학,기술', '산림']\n",
        "df = df[df['category'].isin(c_list)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "WWqh7V8js9vZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fef4a1-4096-45ca-bf40-e3d3bd1f83ad"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    291118.000000\n",
            "mean         65.231683\n",
            "std          52.701358\n",
            "min           4.000000\n",
            "25%          26.000000\n",
            "50%          51.000000\n",
            "75%          89.000000\n",
            "max        1295.000000\n",
            "Name: 한국어, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/KB/df_v1.0.csv\", index=False)"
      ],
      "metadata": {
        "id": "TPpyjLqyEez9"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> df v1.0 END"
      ],
      "metadata": {
        "id": "sYqOQfvqKn8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/KB/df_v1.0.csv')"
      ],
      "metadata": {
        "id": "bhdOj7mHKmrt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'DeepL이 할 수 있는 것' 전성기 맞은 기계번역의 가능성과 한계\n",
        "https://www.ciokorea.com/news/286327\n",
        "\t기계 번역의 주요 함정은 다음과 같다\n",
        "\t생략된 부정사나 잘못된 참조, 번역되지 않거나 알 수 없는 단어\n",
        "\t문장의 일부가 생략, 텍스트가 마음대로 추가\n",
        "\t기계 번역은 원본 텍스트에 모호한 부분이 있으면, 입력 텍스트에 대해 통계적으로 가장 가능성이 높은 번역을 제공\n",
        "\n",
        "변길자. (2021). 기계번역을 활용한 한영번역에서의 번역품질 비교연구. 영어영문학, 26(3), 233-259.\n",
        "파파고의 활용한 한글 원문 오류 : 한글 원문 자체를 이해하는 어려움 때문에 발생하는 오류 와 한글을 영어로 번역하기 어려운 표현이나 문장구조 때문에 발생하는 오류로 구분할 수 있을 것이다.\n",
        "한국어는 예측 가능한 주어는 생략이 가능하다. 번역원 문으로 제시된 이 자료도 섬을 소개하는 정보적 텍스트이기는 하지만 주어 생략, 많은 한자어 사용, 지시 관계의 불명확성으로 인하여 문장이해에 어려움을 주고 있어서 원문 자체를 오해하여 잘못 번역한 경우가 많았다. 더 나아가 어떤 문장 은 접속사 연결이 불분명하고 문장구조가 복잡하여 영문으로 번역하는데 까다로 운 문장구조를 보여주고 있다. 이런 이유로 기계번역 자체가 원문을 영문번역 할 때 오류를 보여주고 있으며, 원문을 제대로 이해하지 못하면 프리에디팅 기 법이든 포스트에디팅 기법이든 아니면 두 가지 방식을 혼용하여도 번역오류 가 능성을 보여주고 있다.\n",
        "\n",
        "1)\t단어 오류 : 단어의미 인지상의 오류로 한자 등 한국어 단어의 의미를 제대로 이해하지 못 하여 오류를 범한 예이다\n",
        "A.\t예시 : 그는 유명을 달리하기 전 비금도를 진정한 고향이라 불렀다.\n",
        "2)\t문맥 오류 : 문맥 인지상의 오류로 원문에 생략되었기 때문에 문맥을 제대로 파악하지 못 하여 오류를 범한 경우로 주어파악 오류, 지시사 오류, 대명사 오류 등이 속한다\n",
        "A.\t예시 : 이 섬에서 초등학교를 졸업했고 다시 뭍으로 향했다.\n",
        "3)\t문장 오류 : 문장접속 인지상의 오류로 한글 원문에 접속사가 많아서 문장의 의미를 제대 로 파악하지 못하여 문장 전체가 오류를 범한 예이다.\n",
        "A.\t예시 : 부모가 살았던 곳이기도 했지만, 경기도 포천군 지현리에 서재가 있 었고 이 인근 소나무 수목장에 안장됐음에도 이유는 분명했다.\n",
        "\n",
        "Major Errors in MT:\n",
        "\n",
        "\"MQM results are mainly driven by major and accuracy errors. The majority of major errors are accuracy errors. This suggests the quality of an MT system is still driven mostly by accuracy errors as most fluency errors are judged minor.\" [Page 7]\n",
        "Error Category Descriptions:\n",
        "\n",
        "Accuracy Errors:\n",
        "Addition: \"Translation includes information not present in the source.\"\n",
        "Omission: \"Translation is missing content from the source.\"\n",
        "Mistranslation: \"Translation does not accurately represent the source.\"\n",
        "Untranslated text: \"Source text has been left untranslated.\"\n",
        "Fluency Errors:\n",
        "Punctuation: \"Incorrect punctuation (for locale or style).\"\n",
        "Spelling: \"Incorrect spelling or capitalization.\"\n",
        "Grammar: \"Problems with grammar, other than orthography.\" [Page 16-17]\n",
        "Conclusion on MT Quality:\n",
        "\n",
        "\"Unlike ratings acquired by crowd-worker and ratings acquired by professional translators on simpler human evaluation methodologies, MQM labels acquired with professional translators show a large gap between the quality of human and machine-generated translations. This demonstrates that MT is still far from human parity.\" [Page 12]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "fIskZ_3lU4Ue",
        "outputId": "df341f06-add6-4a31-d387-c1cba01d6693"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-81-cf302af6400a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \t기계 번역의 주요 함정은 다음과 같다\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+F06C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "원문 : Few people are completely satisfied with the current reality\n",
        "정답 : 현실에 완전히 만족하며 살아가는 사람은 거의 없다.\n",
        "오류 :\n",
        "\n",
        "원문 : You should not consume more than 200mg of magnesium per day\n",
        "정답 : 하루에 마그네슘 200mg 이상 섭취하시면 안됩니다.\n",
        "오류 :\n",
        "\n",
        "이를 주어진 조건에서 오류를 생성하고 결과만을 반환해줘\n",
        "Let's think step by step\n",
        "\n",
        "1) 원문을 바탕으로 영어에서 한국어를 번역할 때 기계 번역에서 흔히 생기는 오류를 고려\n",
        "2) 주어진 조건과 배경을 기반으로 정답을 기반으로 오류문에 생길 수 있는 오류를 고려\n",
        "3) 오류문을 1)과 2)를 바탕으로 생성\n",
        "4) 판단 절차에 따라 오류문을 판단\n",
        "5) 해당 결과와 3)에서 생성된 오류문의 타입과 범주과 다르다면 처음부터 다시 시작, 같다면 다음 단계로 이동\n",
        "6) 주어진 format으로 출력\n",
        "\n",
        "결과 format은 다음과 같아\n",
        "범주 :\n",
        "타입 :\n",
        "오류문 :\n",
        "\n",
        "배경은 \"\"\"을 통해 구분되어 있어\n",
        "판단 절차는 <>을 통해 구분되어 있어\n",
        "조건은 '''을 통해 구분되어 있어\n",
        "\n",
        "조건 '''\n",
        "1) 범주의 경우 Major와 Minor를 가장 선호, 그 뒤로 Neutral, Critical\n",
        "2) 타입을 경우 기계 번역에서 흔히 생기는 오류를 고려해서 정함\n",
        "'''\n",
        "판단 절차 :\n",
        "<\n",
        "1. 각기 다른 배경의 전문가 5명이 있어, 각 전문가는 해당 문제를 보고 어떤 범주에 속하며 타입이 뭔지 판단을 해\n",
        "2. 각자 판단에 대해 한번 더 검토를 진행하며, 명확하게 분류를 진행해\n",
        "3. 각 전문가의 결과를 취합하고 가장 선택을 많이 받은 결과를 반환해\n",
        ">\n",
        "\n",
        "배경 :\n",
        "\"\"\"\n",
        "오류는 범주와 타입으로 구성되어 있어\n",
        "예시)\n",
        "타입 : 과소 번역\n",
        "범주 : major\n",
        "정답 : 요크셔테리어 한 마리가 병원에 왔다.\n",
        "오류 : 강아지 한 마리가 병원에 왔다.\n",
        "\n",
        "타입 :\n",
        "추가(ADDITION) : 원문에 없는 내용이 추가로 붙은 경우\n",
        "오역(MIS-TRANSLATION) : 번역문의 의미를 잘못 해석한 경우\n",
        "누락(OMMISSION) : 원문의 일부를 아예 번역을 생략한 경우\n",
        "과소 번역(UNDER-TRANSLATION) : 번역문의 의미를 축소해서 번역한 경우\n",
        "과잉 번역(OVER-TRANSLATION) : 번역문의 의미를 과대하게 변역한 경우\n",
        "\n",
        "범주 :\n",
        "Critical\n",
        "Non-translation: 원문의 내용이 전혀 번역되지 않았을 때.\n",
        "의미상 심각한 훼손: 원문의 의미와 전혀 다른 방향으로 번역되었거나, 중요한 단어나 개념의 잘못된 번역으로 크게 왜곡되었을 때.\n",
        "예: \"Yes\"를 \"아니요\"로 번역하는 경우.\n",
        "Major\n",
        "의미의 상당한 변화: 원문의 의미와는 다르게 번역되어 독자에게 혼란을 줄 수 있는 오류. 문장의 중요 의미가 훼손되진 않음\n",
        "예: 중요한 조치사항이 잘못된 맥락으로 번역되는 경우.\n",
        "중복 번역: 동일한 단어나 구절이 불필요하게 반복되어 번역되는 경우.\n",
        "Minor\n",
        "자연스러움의 결여: 번역문이 부자연스러워 문장을 이해하는 데 어려움이 없지만 읽기 불편할 때.\n",
        "예: 어색한 표현 사용이나 불필요한 반복.\n",
        "스타일 및 유창성의 결여: 원문의 톤이나 스타일과 다르게 번역되거나, 문장의 유창성이나 명확성이 저하되는 경우.\n",
        "Neutral\n",
        "선호하는 스타일의 적용: 검토자나 번역가의 개인적인 선호에 따른 스타일 변경이나 선택적 번역.\n",
        "추가적인 정보나 주석: 원문의 내용과 직접적인 관련이 없는 추가 정보나 주석.\n",
        "문맥에 따른 선택적 번역: 여러 가지 번역이 가능한 경우 하나를 선택한 것이며, 선택한 번역이 오류는 아니지만 원문과 완전히 일치하지는 않는 경우.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "6B2qEpzqUy0x",
        "outputId": "c552ed52-a40b-494b-eaf6-8a2c260dcad6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-80-0327c818be29>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    1. 각기 다른 배경의 전문가 5명이 있어, 각 전문가는 해당 문제를 보고 어떤 범주에 속하며 타입이 뭔지 판단을 해\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "mBTQ0ZWWsWGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "\n",
        "def make_list(data):\n",
        "  text = \"뉴스 리스트: \"\n",
        "  for i in range(len(data)):\n",
        "    text += f\"{i+1}: {data[i]} \"\n",
        "\n",
        "  return text\n",
        "\n",
        "def get_completion_multi(text_list, model=\"gpt-3.5-turbo\"):\n",
        "  background = \"\"\"\n",
        "  Your task is to perform the following actions:\n",
        "  1 - From the given 뉴스 리스트, select news related to the economy, investment, policy, and regulation.\n",
        "  2 - Explain the impact the curated news could have on the bank.\n",
        "\n",
        "  keep your explanation to a maximum of 3 sentences\n",
        "\n",
        "  Make your response in Korean\n",
        "\n",
        "  Use the following format:\n",
        "  news: <news number>\n",
        "  categories: <Only one most relevant field 경제 or 투자 or 정책 or 규제>\n",
        "  explanation: <explanation>\n",
        "\n",
        "  If none of the news is curated in the news list, follow this format :\n",
        "  news: <0>\n",
        "  categories: <None>\n",
        "  explanation: <None>\n",
        "  \"\"\"\n",
        "\n",
        "  messages = [\n",
        "      # {\"role\": \"user\", \"content\": background},\n",
        "      {\"role\": \"user\", \"content\": background + text_list + \"Tell me the result for each selected article in the given format\"},\n",
        "      # {\"role\": \"user\", \"content\": text_list},\n",
        "      # {\"role\": \"user\", \"content\": \"Tell me the result for each selected article in the given format\"}\n",
        "      ]\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=0, # this is the degree of randomness of the model's output\n",
        "  )\n",
        "  return response.choices[0].message[\"content\"]\n",
        "\n",
        "sample_df = pd.DataFrame(columns=['news','categories','explanation'])\n",
        "\n",
        "for i in range(0,len(data),20):\n",
        "  print(f\"now: {i} to {len(data)}\")\n",
        "  text_list = make_list(data[i:i+20])\n",
        "  try:\n",
        "    response = get_completion_multi(text_list)\n",
        "  except:\n",
        "    time.sleep(5)\n",
        "    continue\n",
        "  answer = response.split(\"\\n\\n\")\n",
        "  for a in answer:\n",
        "    n,c,e = a.split(\"\\n\")\n",
        "    n = int(n.replace(\"news:\", \"\").strip()) + (i - 1)\n",
        "    c = re.sub(r'\\d+\\.\\s|categories:\\s', '', c).strip()\n",
        "    e = e.replace(\"explanation:\",\"\").strip()\n",
        "    news = data[n] if c != 'None' else 'None'\n",
        "    new_row = pd.DataFrame([[news,c,e]], columns=['news','categories','explanation'])\n",
        "    sample_df = pd.concat([sample_df, new_row])\n",
        "\n",
        "sample_df = sample_df[sample_df['categories'] != 'None']\n",
        "sample_df = sample_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "OFXvu-lqso1z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}